{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b9e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "956058ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(\"http://localhost:6333\") #connecting to local Qdrant instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2c57c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6afe1b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'BAAI/bge-base-en',\n",
       "  'sources': {'hf': 'Qdrant/fast-bge-base-en',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-base-en.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.42,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-base-en-v1.5',\n",
       "  'sources': {'hf': 'qdrant/bge-base-en-v1.5-onnx-q',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-base-en-v1.5.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.21,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-large-en-v1.5',\n",
       "  'sources': {'hf': 'qdrant/bge-large-en-v1.5-onnx',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 1.2,\n",
       "  'additional_files': [],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-small-en',\n",
       "  'sources': {'hf': 'Qdrant/bge-small-en',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/BAAI-bge-small-en.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.13,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-small-en-v1.5',\n",
       "  'sources': {'hf': 'qdrant/bge-small-en-v1.5-onnx-q',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.067,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-small-zh-v1.5',\n",
       "  'sources': {'hf': 'Qdrant/bge-small-zh-v1.5',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-small-zh-v1.5.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Chinese, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.09,\n",
       "  'additional_files': [],\n",
       "  'dim': 512,\n",
       "  'tasks': {}},\n",
       " {'model': 'mixedbread-ai/mxbai-embed-large-v1',\n",
       "  'sources': {'hf': 'mixedbread-ai/mxbai-embed-large-v1',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.64,\n",
       "  'additional_files': [],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-xs',\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-xs',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.09,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-s',\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-s',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.13,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-m',\n",
       "  'sources': {'hf': 'Snowflake/snowflake-arctic-embed-m',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.43,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-m-long',\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-m-long',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 2048 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.54,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-l',\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-l',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 1.02,\n",
       "  'additional_files': [],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-clip-v1',\n",
       "  'sources': {'hf': 'jinaai/jina-clip-v1',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/text_model.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text&image), English, Prefixes for queries/documents: not necessary, 2024 year',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.55,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'Qdrant/clip-ViT-B-32-text',\n",
       "  'sources': {'hf': 'Qdrant/clip-ViT-B-32-text',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text&image), English, 77 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.25,\n",
       "  'additional_files': [],\n",
       "  'dim': 512,\n",
       "  'tasks': {}},\n",
       " {'model': 'sentence-transformers/all-MiniLM-L6-v2',\n",
       "  'sources': {'hf': 'qdrant/all-MiniLM-L6-v2-onnx',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/sentence-transformers-all-MiniLM-L6-v2.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 256 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.09,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-en',\n",
       "  'sources': {'hf': 'xenova/jina-embeddings-v2-base-en',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.52,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-small-en',\n",
       "  'sources': {'hf': 'xenova/jina-embeddings-v2-small-en',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.12,\n",
       "  'additional_files': [],\n",
       "  'dim': 512,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-de',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-de',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model_fp16.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (German, English), 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.32,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-code',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-code',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (English, 30 programming languages), 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.64,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-zh',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-zh',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), supports mixed Chinese-English input text, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.64,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-es',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-es',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), supports mixed Spanish-English input text, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.64,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'thenlper/gte-base',\n",
       "  'sources': {'hf': 'thenlper/gte-base',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'General text embeddings, Unimodal (text), supports English only input text, 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.44,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'thenlper/gte-large',\n",
       "  'sources': {'hf': 'qdrant/gte-large-onnx',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 1.2,\n",
       "  'additional_files': [],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'nomic-ai/nomic-embed-text-v1.5',\n",
       "  'sources': {'hf': 'nomic-ai/nomic-embed-text-v1.5',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.52,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'nomic-ai/nomic-embed-text-v1.5-Q',\n",
       "  'sources': {'hf': 'nomic-ai/nomic-embed-text-v1.5',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model_quantized.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.13,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'nomic-ai/nomic-embed-text-v1',\n",
       "  'sources': {'hf': 'nomic-ai/nomic-embed-text-v1',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.52,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
       "  'sources': {'hf': 'qdrant/paraphrase-multilingual-MiniLM-L12-v2-onnx-Q',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~50 languages), 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2019 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.22,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
       "  'sources': {'hf': 'xenova/paraphrase-multilingual-mpnet-base-v2',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~50 languages), 384 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 1.0,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'intfloat/multilingual-e5-large',\n",
       "  'sources': {'hf': 'qdrant/multilingual-e5-large-onnx',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-multilingual-e5-large.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~100 languages), 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 2.24,\n",
       "  'additional_files': ['model.onnx_data'],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v3',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v3',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Multi-task unimodal (text) embedding model, multi-lingual (~100), 1024 tokens truncation, and 8192 sequence length. Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'cc-by-nc-4.0',\n",
       "  'size_in_GB': 2.29,\n",
       "  'additional_files': ['onnx/model.onnx_data'],\n",
       "  'dim': 1024,\n",
       "  'tasks': {'retrieval.query': 0,\n",
       "   'retrieval.passage': 1,\n",
       "   'separation': 2,\n",
       "   'classification': 3,\n",
       "   'text-matching': 4}}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "TextEmbedding.list_supported_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b02fabfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model\": \"BAAI/bge-small-zh-v1.5\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"Qdrant/bge-small-zh-v1.5\",\n",
      "    \"url\": \"https://storage.googleapis.com/qdrant-fastembed/fast-bge-small-zh-v1.5.tar.gz\",\n",
      "    \"_deprecated_tar_struct\": true\n",
      "  },\n",
      "  \"model_file\": \"model_optimized.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), Chinese, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 0.09,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"Qdrant/clip-ViT-B-32-text\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"Qdrant/clip-ViT-B-32-text\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"model.onnx\",\n",
      "  \"description\": \"Text embeddings, Multimodal (text&image), English, 77 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 0.25,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"jinaai/jina-embeddings-v2-small-en\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"xenova/jina-embeddings-v2-small-en\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"onnx/model.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.\",\n",
      "  \"license\": \"apache-2.0\",\n",
      "  \"size_in_GB\": 0.12,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "\n",
    "for model in TextEmbedding.list_supported_models():\n",
    "    if model[\"dim\"] == EMBEDDING_DIMENSIONALITY:\n",
    "        print(json.dumps(model, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "814dbc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72fca1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the collection name\n",
    "collection_name = \"zoomcamp-rag\"\n",
    "\n",
    "# Create the collection with specified vector parameters\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,  # Dimensionality of the vectors\n",
    "        distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "199668b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "id = 0\n",
    "\n",
    "for course in documents_raw:\n",
    "    for doc in course['documents']:\n",
    "\n",
    "        point = models.PointStruct(\n",
    "            id=id,\n",
    "            vector=models.Document(text=doc['text'], model=model_handle), #embed text locally with \"jinaai/jina-embeddings-v2-small-en\" from FastEmbed\n",
    "            payload={\n",
    "                \"text\": doc['text'],\n",
    "                \"section\": doc['section'],\n",
    "                \"course\": course['course']\n",
    "            } #save all needed metadata fields\n",
    "        )\n",
    "        points.append(point)\n",
    "\n",
    "        id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c460fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07611ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, limit=1):\n",
    "\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document( #embed the query text locally with \"jinaai/jina-embeddings-v2-small-en\"\n",
    "            text=query,\n",
    "            model=model_handle \n",
    "        ),\n",
    "        limit=limit, # top closest matches\n",
    "        with_payload=True #to get metadata in the results\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5c1ffd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"One main reason behind that, is the way of splitting data. For example, we want to split data into train/validation/test with the ratios 60%/20%/20% respectively.\\nAlthough the following two options end up with the same ratio, the data itself is a bit different and not 100% matching in each case.\\n1)\\ndf_train, df_temp = train_test_split(df, test_size=0.4, random_state=42)\\ndf_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=42)\\n2)\\ndf_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\\ndf_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)\\nTherefore, I would recommend using the second method which is more consistent with the lessons and thus the homeworks.\\nIbraheem Taha\",\n",
      "  \"section\": \"4. Evaluation Metrics for Classification\",\n",
      "  \"question\": \"Why do I have different values of accuracy than the options in the homework?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "course = random.choice(documents_raw)\n",
    "course_piece = random.choice(course['documents'])\n",
    "print(json.dumps(course_piece, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a49adea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search(course_piece['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "620e34d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryResponse(points=[ScoredPoint(id=530, version=0, score=0.83668727, payload={'text': 'For Q5 in homework, should we calculate the smallest difference in accuracy in real values (i.e. -0.001 is less than -0.0002) or in absolute values (i.e. 0.0002 is less than 0.001)?\\nWe should select the “smallest” difference, and not the “lowest”, meaning we should reason in absolute values.\\nIf the difference is negative, it means that the model actually became better when we removed the feature.', 'section': '3. Machine Learning for Classification', 'course': 'machine-learning-zoomcamp'}, vector=None, shard_key=None, order_value=None)])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0674731a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Why do I have different values of accuracy than the options in the homework?\n",
      "\n",
      "Top Retrieved Answer:\n",
      "For Q5 in homework, should we calculate the smallest difference in accuracy in real values (i.e. -0.001 is less than -0.0002) or in absolute values (i.e. 0.0002 is less than 0.001)?\n",
      "We should select the “smallest” difference, and not the “lowest”, meaning we should reason in absolute values.\n",
      "If the difference is negative, it means that the model actually became better when we removed the feature.\n",
      "\n",
      "Original Answer:\n",
      "One main reason behind that, is the way of splitting data. For example, we want to split data into train/validation/test with the ratios 60%/20%/20% respectively.\n",
      "Although the following two options end up with the same ratio, the data itself is a bit different and not 100% matching in each case.\n",
      "1)\n",
      "df_train, df_temp = train_test_split(df, test_size=0.4, random_state=42)\n",
      "df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=42)\n",
      "2)\n",
      "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
      "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)\n",
      "Therefore, I would recommend using the second method which is more consistent with the lessons and thus the homeworks.\n",
      "Ibraheem Taha\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question:\\n{course_piece['question']}\\n\")\n",
    "print(\"Top Retrieved Answer:\\n{}\\n\".format(result.points[0].payload['text']))\n",
    "print(\"Original Answer:\\n{}\".format(course_piece['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8063ad44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\n",
      "Older news:[source1] [source2]\n"
     ]
    }
   ],
   "source": [
    "print(search(\"What if I submit homeworks late?\").points[0].payload['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1aa3be1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=2, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\" # exact matching on string metadata fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bdca9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_in_course(query, course=\"mlops-zoomcamp\", limit=1):\n",
    "\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document( #embed the query text locally with \"jinaai/jina-embeddings-v2-small-en\"\n",
    "            text=query,\n",
    "            model=model_handle\n",
    "        ),\n",
    "        query_filter=models.Filter( # filter by course name\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\",\n",
    "                    match=models.MatchValue(value=course)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=limit, # top closest matches\n",
    "        with_payload=True #to get metadata in the results\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03e6cba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\n",
      "Older news:[source1] [source2]\n"
     ]
    }
   ],
   "source": [
    "print(search_in_course(\"What if I submit homeworks late?\", \"data-engineering-zoomcamp\").points[0].payload['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b3c4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
